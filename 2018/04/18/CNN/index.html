<!DOCTYPE html>
<html style="display: none;" lang="zh">
    <head>
    <meta charset="utf-8">
    <!--
        © Material Theme
        https://github.com/viosey/hexo-theme-material
        Version: 1.5.6 -->
    <script>
        window.materialVersion = "1.5.6"
        // Delete localstorage with these tags
        window.oldVersion = [
            'codestartv1',
            '1.3.4',
            '1.4.0',
            '1.4.0b1',
            '1.5.0',
            '1.5.2',
            '1.5.5'
        ]
    </script>

    <!-- dns prefetch -->
    <meta http-equiv="x-dns-prefetch-control" content="on">






    <link rel="dns-prefetch" href="https://cdn-city.livere.com"/>






    <link rel="dns-prefetch" href="https://fonts.proxy.ustclug.org"/>





    <!-- Meta & Info -->
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="renderer" content="webkit">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!-- Title -->
    
    <title>
        
            卷积神经网络CNN | 
        
        Hey~YaHei!
    </title>

    <!-- Favicons -->
    <link rel="icon shortcut" type="image/ico" href="/img/favicon.png">
    <link rel="icon" href="/img/favicon.png">

    <meta name="format-detection" content="telephone=no"/>
    <meta name="description" itemprop="description" content="">
    <meta name="keywords" content=",《Handson-ML》笔记">
    <meta name="theme-color" content="#0097A7">

    <!-- Disable Fucking Bloody Baidu Tranformation -->
    <meta http-equiv="Cache-Control" content="no-transform" />
    <meta http-equiv="Cache-Control" content="no-siteapp" />

    <!--[if lte IE 9]>
        <link rel="stylesheet" href="/css/ie-blocker.css">

        
            <script src="/js/ie-blocker.zhCN.js"></script>
        
    <![endif]-->

    <!-- Import lsloader -->
    <script>(function(){window.lsloader={jsRunSequence:[],jsnamemap:{},cssnamemap:{}};lsloader.removeLS=function(a){try{localStorage.removeItem(a)}catch(b){}};lsloader.setLS=function(a,c){try{localStorage.setItem(a,c)}catch(b){}};lsloader.getLS=function(a){var c="";try{c=localStorage.getItem(a)}catch(b){c=""}return c};versionString="/*"+(window.materialVersion||"unknownVersion")+"*/";lsloader.clean=function(){try{var b=[];for(var a=0;a<localStorage.length;a++){b.push(localStorage.key(a))}b.forEach(function(e){var f=lsloader.getLS(e);if(window.oldVersion){var d=window.oldVersion.reduce(function(g,h){return g||f.indexOf("/*"+h+"*/")!==-1},false);if(d){lsloader.removeLS(e)}}})}catch(c){}};lsloader.clean();lsloader.load=function(f,a,b,d){if(typeof b==="boolean"){d=b;b=undefined}d=d||false;b=b||function(){};var e;e=this.getLS(f);if(e&&e.indexOf(versionString)===-1){this.removeLS(f);this.requestResource(f,a,b,d);return}if(e){var c=e.split(versionString)[0];if(c!=a){console.log("reload:"+a);this.removeLS(f);this.requestResource(f,a,b,d);return}e=e.split(versionString)[1];if(d){this.jsRunSequence.push({name:f,code:e});this.runjs(a,f,e)}else{document.getElementById(f).appendChild(document.createTextNode(e));b()}}else{this.requestResource(f,a,b,d)}};lsloader.requestResource=function(b,e,a,c){var d=this;if(c){this.iojs(e,b,function(h,f,g){d.setLS(f,h+versionString+g);d.runjs(h,f,g)})}else{this.iocss(e,b,function(f){document.getElementById(b).appendChild(document.createTextNode(f));d.setLS(b,e+versionString+f)},a)}};lsloader.iojs=function(d,b,g){var a=this;a.jsRunSequence.push({name:b,code:""});try{var f=new XMLHttpRequest();f.open("get",d,true);f.onreadystatechange=function(){if(f.readyState==4){if((f.status>=200&&f.status<300)||f.status==304){if(f.response!=""){g(d,b,f.response);return}}a.jsfallback(d,b)}};f.send(null)}catch(c){a.jsfallback(d,b)}};lsloader.iocss=function(f,c,h,a){var b=this;try{var g=new XMLHttpRequest();g.open("get",f,true);g.onreadystatechange=function(){if(g.readyState==4){if((g.status>=200&&g.status<300)||g.status==304){if(g.response!=""){h(g.response);a();return}}b.cssfallback(f,c,a)}};g.send(null)}catch(d){b.cssfallback(f,c,a)}};lsloader.iofonts=function(f,c,h,a){var b=this;try{var g=new XMLHttpRequest();g.open("get",f,true);g.onreadystatechange=function(){if(g.readyState==4){if((g.status>=200&&g.status<300)||g.status==304){if(g.response!=""){h(g.response);a();return}}b.cssfallback(f,c,a)}};g.send(null)}catch(d){b.cssfallback(f,c,a)}};lsloader.runjs=function(f,c,e){if(!!c&&!!e){for(var b in this.jsRunSequence){if(this.jsRunSequence[b].name==c){this.jsRunSequence[b].code=e}}}if(!!this.jsRunSequence[0]&&!!this.jsRunSequence[0].code&&this.jsRunSequence[0].status!="failed"){var a=document.createElement("script");a.appendChild(document.createTextNode(this.jsRunSequence[0].code));a.type="text/javascript";document.getElementsByTagName("head")[0].appendChild(a);this.jsRunSequence.shift();if(this.jsRunSequence.length>0){this.runjs()}}else{if(!!this.jsRunSequence[0]&&this.jsRunSequence[0].status=="failed"){var d=this;var a=document.createElement("script");a.src=this.jsRunSequence[0].path;a.type="text/javascript";this.jsRunSequence[0].status="loading";a.onload=function(){d.jsRunSequence.shift();if(d.jsRunSequence.length>0){d.runjs()}};document.body.appendChild(a)}}};lsloader.tagLoad=function(b,a){this.jsRunSequence.push({name:a,code:"",path:b,status:"failed"});this.runjs()};lsloader.jsfallback=function(c,b){if(!!this.jsnamemap[b]){return}else{this.jsnamemap[b]=b}for(var a in this.jsRunSequence){if(this.jsRunSequence[a].name==b){this.jsRunSequence[a].code="";this.jsRunSequence[a].status="failed";this.jsRunSequence[a].path=c}}this.runjs()};lsloader.cssfallback=function(e,c,b){if(!!this.cssnamemap[c]){return}else{this.cssnamemap[c]=1}var d=document.createElement("link");d.type="text/css";d.href=e;d.rel="stylesheet";d.onload=d.onerror=b;var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(d,a)};lsloader.runInlineScript=function(c,b){var a=document.getElementById(b).innerText;this.jsRunSequence.push({name:c,code:a});this.runjs()}})();</script>

    <!-- Import queue -->
    <script>function Queue(){this.dataStore=[];this.offer=b;this.poll=d;this.execNext=a;this.debug=false;this.startDebug=c;function b(e){if(this.debug){console.log("Offered a Queued Function.")}if(typeof e==="function"){this.dataStore.push(e)}else{console.log("You must offer a function.")}}function d(){if(this.debug){console.log("Polled a Queued Function.")}return this.dataStore.shift()}function a(){var e=this.poll();if(e!==undefined){if(this.debug){console.log("Run a Queued Function.")}e()}}function c(){this.debug=true}}var queue=new Queue();</script>

    <!-- Import CSS -->
    
        <style id="material_css"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("material_css","/css/material.min.css?Z7a72R1E4SxzBKR/WGctOA==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>
        <style id="style_css"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("style_css","/css/style.min.css?NKhlKQkXw/c66TR5p4wO+w==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>

        

    

    

    <!-- Config CSS -->

<!-- Other Styles -->
<style>
  body, html {
    font-family: Roboto, "Helvetica Neue", Helvetica, "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei", "微软雅黑", Arial, sans-serif;
    overflow-x: hidden !important;
  }
  
  code {
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  }

  a {
    color: #00838F;
  }

  .mdl-card__media,
  #search-label,
  #search-form-label:after,
  #scheme-Paradox .hot_tags-count,
  #scheme-Paradox .sidebar_archives-count,
  #scheme-Paradox .sidebar-colored .sidebar-header,
  #scheme-Paradox .sidebar-colored .sidebar-badge{
    background-color: #0097A7 !important;
  }

  /* Sidebar User Drop Down Menu Text Color */
  #scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:hover,
  #scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:focus {
    color: #0097A7 !important;
  }

  #post_entry-right-info,
  .sidebar-colored .sidebar-nav li:hover > a,
  .sidebar-colored .sidebar-nav li:hover > a i,
  .sidebar-colored .sidebar-nav li > a:hover,
  .sidebar-colored .sidebar-nav li > a:hover i,
  .sidebar-colored .sidebar-nav li > a:focus i,
  .sidebar-colored .sidebar-nav > .open > a,
  .sidebar-colored .sidebar-nav > .open > a:hover,
  .sidebar-colored .sidebar-nav > .open > a:focus,
  #ds-reset #ds-ctx .ds-ctx-entry .ds-ctx-head a {
    color: #0097A7 !important;
  }

  .toTop {
    background: #757575 !important;
  }

  .material-layout .material-post>.material-nav,
  .material-layout .material-index>.material-nav,
  .material-nav a {
    color: #757575;
  }

  #scheme-Paradox .MD-burger-layer {
    background-color: #757575;
  }

  #scheme-Paradox #post-toc-trigger-btn {
    color: #757575;
  }

  .post-toc a:hover {
    color: #00838F;
    text-decoration: underline;
  }

</style>


<!-- Theme Background Related-->

    <style>
      body{
        background-color: #F5F5F5;
      }

      /* blog_info bottom background */
      #scheme-Paradox .material-layout .something-else .mdl-card__supporting-text{
        background-color: #fff;
      }
    </style>




<!-- Fade Effect -->

    <style>
      .fade {
        transition: all 800ms linear;
        -webkit-transform: translate3d(0,0,0);
        -moz-transform: translate3d(0,0,0);
        -ms-transform: translate3d(0,0,0);
        -o-transform: translate3d(0,0,0);
        transform: translate3d(0,0,0);
        opacity: 1;
      }

      .fade.out{
        opacity: 0;
      }
    </style>


<!-- Import Font -->
<!-- Import Roboto -->

    <link href="https://fonts.proxy.ustclug.org/css?family=Roboto:300,400,500" rel="stylesheet">


<!-- Import Material Icons -->


    <style id="material_icons"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("material_icons","/css/material-icons.css?pqhB/Rd/ab0H2+kZp0RDmw==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>




    <!-- Import jQuery -->
    
        <script>lsloader.load("jq_js","https://cdn.bootcss.com/jquery/2.2.0/jquery.min.js", true)</script>
    

    <!-- WebAPP Icons -->
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="application-name" content="Hey~YaHei!">
    <meta name="msapplication-starturl" content="http://hey-yahei.cn/2018/04/18/CNN/">
    <meta name="msapplication-navbutton-color" content="#0097A7">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-title" content="Hey~YaHei!">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon" href="/img/favicon.png">

    <!-- Site Verification -->
    <meta name="google-site-verification" content="9RYmZ6xORQYm4BISDRGPi57Oj0NzoKAN-U9ZR6UxSxY" />
    <meta name="baidu-site-verification" content="xij8ev3DGx" />

    <!-- RSS -->
    
        
            <link rel=alternate type="application/rss+xml" href="/rss2.xml">
        
    

    <!-- The Open Graph protocol -->
    <meta property="og:url" content="http://hey-yahei.cn/2018/04/18/CNN/">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="卷积神经网络CNN | Hey~YaHei!">
    <meta property="og:image" content="/img/favicon.png">
    <meta property="og:description" content="">
    <meta property="og:article:tag" content="《Handson-ML》笔记"> 

    
        <meta property="article:published_time" content="Wed Apr 18 2018 00:00:00 GMT+0800">
        <meta property="article:modified_time" content="Fri Aug 24 2018 12:31:59 GMT+0800">
    

    <!-- The Twitter Card protocol -->
    <meta name="twitter:card" content="summary_large_image">

    <!-- Add canonical link for SEO -->
    
        <link rel="canonical" href="http://hey-yahei.cn/2018/04/18/CNN/index.html" />
    

    <!-- Structured-data for SEO -->
    
        


<script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "mainEntityOfPage": "http://hey-yahei.cn/2018/04/18/CNN/index.html",
    "headline": "卷积神经网络CNN",
    "datePublished": "Wed Apr 18 2018 00:00:00 GMT+0800",
    "dateModified": "Fri Aug 24 2018 12:31:59 GMT+0800",
    "author": {
        "@type": "Person",
        "name": "YaHei",
        "image": {
            "@type": "ImageObject",
            "url": "/imgs/avatar2.jpg"
        },
        "description": "Hey!"
    },
    "publisher": {
        "@type": "Organization",
        "name": "Hey~YaHei!",
        "logo": {
            "@type":"ImageObject",
            "url": "/img/favicon.png"
        }
    },
    "keywords": ",《Handson-ML》笔记",
    "description": "",
}
</script>


    

    <!-- Analytics -->
    
    
    

    <!-- Custom Head -->
    

<link rel="stylesheet" href="/css/prism.css" type="text/css"></head>


    
        <body id="scheme-Paradox" class="lazy">
            <div class="material-layout  mdl-js-layout has-drawer is-upgraded">
                

                <!-- Main Container -->
                <main class="material-layout__content" id="main">

                    <!-- Top Anchor -->
                    <div id="top"></div>

                    
                        <!-- Hamburger Button -->
                        <button class="MD-burger-icon sidebar-toggle">
                            <span id="MD-burger-id" class="MD-burger-layer"></span>
                        </button>
                    

                    <!-- Post TOC -->

    
    <!-- Back Button -->
    <!--
    <div class="material-back" id="backhome-div" tabindex="0">
        <a class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon"
           href="#" onclick="window.history.back();return false;"
           target="_self"
           role="button"
           data-upgraded=",MaterialButton,MaterialRipple">
            <i class="material-icons" role="presentation">arrow_back</i>
            <span class="mdl-button__ripple-container">
                <span class="mdl-ripple"></span>
            </span>
        </a>
    </div>
    -->


    <!-- Left aligned menu below button -->
    
    
    <button id="post-toc-trigger-btn"
        class="mdl-button mdl-js-button mdl-button--icon">
        <i class="material-icons">format_list_numbered</i>
    </button>

    <ul class="post-toc-wrap mdl-menu mdl-menu--bottom-left mdl-js-menu mdl-js-ripple-effect" for="post-toc-trigger-btn" style="max-height:80vh; overflow-y:scroll;">
        <ol class="post-toc"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#CNN原理"><span class="post-toc-number">1.</span> <span class="post-toc-text">CNN原理</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#反向传播"><span class="post-toc-number">1.1.</span> <span class="post-toc-text">反向传播</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#卷积层（Conv）"><span class="post-toc-number">1.2.</span> <span class="post-toc-text">卷积层（Conv）</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#池化层（Pool）"><span class="post-toc-number">1.3.</span> <span class="post-toc-text">池化层（Pool）</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#全连接层（Fully-Connection）"><span class="post-toc-number">1.4.</span> <span class="post-toc-text">全连接层（Fully Connection）</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#tensorflow实现"><span class="post-toc-number">2.</span> <span class="post-toc-text">tensorflow实现</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#卷积层"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">卷积层</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#池化层"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">池化层</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#内存占用计算（以卷积层为例）"><span class="post-toc-number">3.</span> <span class="post-toc-text">内存占用计算（以卷积层为例）</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#经典的CNN分类架构"><span class="post-toc-number">4.</span> <span class="post-toc-text">经典的CNN分类架构</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#目标检测架构"><span class="post-toc-number">5.</span> <span class="post-toc-text">目标检测架构</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#CNN可视化"><span class="post-toc-number">6.</span> <span class="post-toc-text">CNN可视化</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#网络压缩"><span class="post-toc-number">7.</span> <span class="post-toc-text">网络压缩</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#数据扩充"><span class="post-toc-number">8.</span> <span class="post-toc-text">数据扩充</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#简单的数据扩充"><span class="post-toc-number">8.1.</span> <span class="post-toc-text">简单的数据扩充</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#特殊的数据扩充"><span class="post-toc-number">8.2.</span> <span class="post-toc-text">特殊的数据扩充</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#图像预处理：中心式归一化"><span class="post-toc-number">9.</span> <span class="post-toc-text">图像预处理：中心式归一化</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#超参数设定"><span class="post-toc-number">10.</span> <span class="post-toc-text">超参数设定</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#输入数据像素大小"><span class="post-toc-number">10.1.</span> <span class="post-toc-text">输入数据像素大小</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#卷积层参数"><span class="post-toc-number">10.2.</span> <span class="post-toc-text">卷积层参数</span></a></li><li class="post-toc-item post-toc-level-4"><a class="post-toc-link" href="#池化层参数"><span class="post-toc-number">10.3.</span> <span class="post-toc-text">池化层参数</span></a></li></ol></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#训练技巧"><span class="post-toc-number">11.</span> <span class="post-toc-text">训练技巧</span></a></li></ol>
    </ul>
    




<!-- Layouts -->

    <!-- Post Module -->
    <div class="material-post_container">

        <div class="material-post mdl-grid">
            <div class="mdl-card mdl-shadow--4dp mdl-cell mdl-cell--12-col">

                <!-- Post Header(Thumbnail & Title) -->
                
    <!-- Paradox Post Header -->
    
        
            <!-- Random Thumbnail -->
            <div class="post_thumbnail-random mdl-card__media mdl-color-text--grey-50">
            <script type="text/ls-javascript" id="post-thumbnail-script">
    var randomNum = Math.floor(Math.random() * 19 + 1);

    $('.post_thumbnail-random').attr('data-original', '/img/random/material-' + randomNum + '.png');
    $('.post_thumbnail-random').addClass('lazy');
</script>

        
    
            <p class="article-headline-p">
                卷积神经网络CNN
            </p>
        </div>





                
                    <!-- Paradox Post Info -->
                    <div class="mdl-color-text--grey-700 mdl-card__supporting-text meta">

    <!-- Author Avatar -->
    <div id="author-avatar">
        <img src="/imgs/avatar2.jpg" width="44px" height="44px" alt="Author Avatar"/>
    </div>
    <!-- Author Name & Date -->
    <div>
        <strong>YaHei</strong>
        <span>4月 18, 2018</span>
    </div>

    <div class="section-spacer"></div>

    <!-- Favorite -->
    <!--
        <button id="article-functions-like-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon btn-like">
            <i class="material-icons" role="presentation">favorite</i>
            <span class="visuallyhidden">favorites</span>
        </button>
    -->

    <!-- Qrcode -->
    

    <!-- Tags (bookmark) -->
    
    <button id="article-functions-viewtags-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon">
        <i class="material-icons" role="presentation">bookmark</i>
        <span class="visuallyhidden">bookmark</span>
    </button>
    <ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-functions-viewtags-button">
        <li class="mdl-menu__item">
        <a class="post_tag-link" href="/tags/《Handson-ML》笔记/">《Handson-ML》笔记</a>
    </ul>
    

    <!-- Share -->
    
        <button id="article-fuctions-share-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon">
    <i class="material-icons" role="presentation">share</i>
    <span class="visuallyhidden">share</span>
</button>
<ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-fuctions-share-button">
    

    

    <!-- Share Weibo -->
    
        <a class="post_share-link" href="http://service.weibo.com/share/share.php?appkey=&title=卷积神经网络CNN&url=http://hey-yahei.cn/2018/04/18/CNN/index.html&pic=http://hey-yahei.cn/img/favicon.png&searchPic=false&style=simple" target="_blank">
            <li class="mdl-menu__item">
                分享到微博
            </li>
        </a>
    

    <!-- Share Twitter -->
    

    <!-- Share Facebook -->
    

    <!-- Share Google+ -->
    

    <!-- Share LinkedIn -->
    

    <!-- Share QQ -->
    
        <a class="post_share-link" href="http://connect.qq.com/widget/shareqq/index.html?site=Hey~YaHei!&title=卷积神经网络CNN&summary=&pics=http://hey-yahei.cn/img/favicon.png&url=http://hey-yahei.cn/2018/04/18/CNN/index.html" target="_blank">
            <li class="mdl-menu__item">
                分享到 QQ
            </li>
        </a>
    

    <!-- Share Telegram -->
    
</ul>

    
</div>

                

                <!-- Post Content -->
                <div id="post-content" class="mdl-color-text--grey-700 mdl-card__supporting-text fade out">
    
        <p><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="298" height="52" src="//music.163.com/outchain/player?type=2&id=458725210&auto=0&height=32"></iframe><br>BGM：<strong>《四月是你的谎言》ED2</strong>        </p>
<hr>
<p>参考：     </p>
<ol>
<li>《<a href="https://book.douban.com/subject/26840215/" target="_blank" rel="noopener">Hands-On Machine Learning with Scikit-Learn and TensorFlow(2017)</a>》Chap13<br> <a href="/2018/04/08/Handson-ML/">《Hands-On Machine Learning with Scikit-Learn and TensorFlow》笔记</a>        </li>
<li>《<a href="https://pan.baidu.com/s/1GF4yLtVphlwFS9by00Ns1Q" target="_blank" rel="noopener">卷积神经网络——深度学习实践手册(2017.05)</a>》      </li>
<li>《<a href="https://book.douban.com/subject/27087503/" target="_blank" rel="noopener">Deep Learning 深度学习(2017)</a>》        </li>
</ol>
<h3 id="CNN原理"><a href="#CNN原理" class="headerlink" title="CNN原理"></a>CNN原理</h3><p>卷积神经网络主要由<strong>卷积层+激活函数+池化层</strong>组成，并且在最后用全连接层输出——<br><img src="/Handson-ML/12CNN.png" alt="12CNN">     </p>
<h4 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h4><p><a href="/ML-Andrew/ML-Andrew-notes3.html#反向传播算法?_blank">机器学习-吴恩达/3 非线性分类器——神经网络/反向传播算法 | Hey~YaHei!</a><br>论文：<a href="http://www.iro.umontreal.ca/~pift6266/A06/refs/backprop_old.pdf" target="_blank" rel="noopener">Learning representation by back-propagating errors(1986)</a>   </p>
<p>前向传播：<br>$$ z_i = \omega_i^T x_{i}  $$<br>其中，<br>$z_i$ 为第i层的损失，即 $z_i = Cost(x_{i+1}, y)$；<br>$x_i$ 为第i层的输入；<br>$\omega_i$ 为第i层的参数；<br>$x_0$ 为原始输入    </p>
<p>根据链式法则，$z_i$ 对参数 $\omega_i$ 和输入 $x_i$ 求偏导——<br>$$ \frac{\partial z_i}{\partial \omega_i} = \frac{\partial z_i}{\partial x_{i+1}} \frac{\partial x_{i+1}}{\partial \omega_i} $$<br>$$ \frac{\partial z_i}{\partial x_i} = \frac{\partial z_i}{\partial x_{i+1}} \frac{\partial x_{i+1}}{\partial x_i} $$<br>其中，<br>由于 $x_{i+1}$ 由 $x_i$ 经过 $\omega_i$ 的作用得到，则 $\frac{\partial x_{i+1}}{\partial \omega_i}$ 和 $\frac{\partial x_{i+1}}{\partial x_i}$ 可以直接求得；<br>剩下的部分 $\frac{\partial z_i}{\partial x_{i+1}}$ 是由后一层计算得到；    </p>
<p>总的来说，误差由后往前传播，<br>$\frac{\partial z_i}{\partial \omega_i}$ 用于梯度下降，如 $\omega_i \gets \omega_i - \eta \frac{\partial z}{\partial \omega_i}$；<br>$\frac{\partial z_i}{\partial x_i}$ 用于前层 $\frac{\partial z_{i-1}}{\partial \omega_{i-1}}$ 的计算     </p>
<p>这里对不同参数的求导操作非常繁琐，Theano、Tensorflow都采用符号微分的方法进行自动求导（编译时就计算得到导数的数学表示）；<br>具体可以参见“花书”《Deep Learning 深度学习》（中文版）P126-139       </p>
<h4 id="卷积层（Conv）"><a href="#卷积层（Conv）" class="headerlink" title="卷积层（Conv）"></a>卷积层（Conv）</h4><p>卷积层并不是使用严格数学意义的卷积运算，而是使用保留卷积性质但抛弃可交换性的互相关函数；<br><em>卷积运算具有可交换性，这在数学证明上是很有用的，但在神经网络的应用中却是一个比较鸡肋的性质</em><br>卷积操作选用一定大小的卷积核（下图黄色区域）在原始数据上移动，与重合部分数据做乘和运算；<br>依次类推，最终输出一张特征图（Feature Map）<br><img src="/Handson-ML/12Convolutional_Kernel.gif" alt="12Convolutional_Kernel">       </p>
<p>卷积核的作用相当一个滤波器，其参数是经过学习得到的，可以用于提取图片中的特征；<br>由于核参数是随机初始化的，所以它们很可能会提取出不同的特征；<br>由低层的卷积层提取简单特征，然后逐层堆叠卷积层，将简单特征逐渐抽象为更高层次的语义概念；       </p>
<p>大核的卷积层可以用多层的小核的卷积层实现；<br>比如用三层3x3卷积核的卷积层可以提取到一层7x7卷积核的卷积层一样的特征——<br><img src="/Handson-ML/12Multi_Conv_Layers.png" alt="12Multi_Conv_Layers"><br>而且，使用多层小核卷积层由以下优势：    </p>
<ol>
<li>减少参数<br> 7x7卷积核有 $7 \times 7 = 49$ 个参数，而三层3x3卷积核只有 $3 \times 3 \times 3 = 27$ 个参数      </li>
<li>增加网络深度<br> 增加网络容量和复杂度    </li>
</ol>
<p>卷积操作的变体：     </p>
<ol>
<li>扩大原有卷积核在前层的感受野<br> 论文：<a href="https://arxiv.org/pdf/1703.06211.pdf" target="_blank" rel="noopener">Deformable Convolutional Networks(2017)</a>     </li>
<li>感受野形状可变（而不再是简单的矩形区域）<br> 论文：<a href="https://arxiv.org/pdf/1511.07122.pdf" target="_blank" rel="noopener">Multi-Scale Context Aggregation by Dilated Convolutions(2016)</a>      </li>
</ol>
<h4 id="池化层（Pool）"><a href="#池化层（Pool）" class="headerlink" title="池化层（Pool）"></a>池化层（Pool）</h4><p>池化操作与卷积操作类似，但池化层是<strong>不需要参数</strong>的；<br>选用一定大小的池化核在原始数据上移动，与重合部分数据做一定的聚合运算（取均值、取最值、按一定概率随机取值等）；<br>依次类推，最终输出一张特征图；       </p>
<p>详见 《<a href="/2018/05/07/漫谈池化层?_blank">漫谈池化层 | Hey~YaHei!</a>》     </p>
<h4 id="全连接层（Fully-Connection）"><a href="#全连接层（Fully-Connection）" class="headerlink" title="全连接层（Fully Connection）"></a>全连接层（Fully Connection）</h4><p>参考：<a href="https://www.zhihu.com/question/41037974" target="_blank" rel="noopener">全连接层的作用是什么？——魏秀参的回答 | 知乎</a>     </p>
<p>全连接层在CNN中起“分类器”作用，将卷积层、池化层、激活函数学到的特征表示映射到样本的标记空间；<br>由于最后一层卷积层输出一个若干个二维数据（总体为三维），所以输入FC前通常需要将其展平（Flatten）为一维；       </p>
<p>实际上，全连接层可以用卷积操作代为实现：      </p>
<ol>
<li>如果FC前为FC，则该FC可以转换成1 x 1的卷积     </li>
<li>如果FC前为卷积层，则该FC可以转换为H x W的卷积（H、W为前层输出的高、宽）       </li>
</ol>
<p>由于全连接层参数冗余，一些网络如ResNet、GoogLeNet等采用全局平均池化（GAP）取代FC来融合学到的深度特征；    </p>
<p>近期研究也发现，FC可以在模型表示能力迁移过程中（尤其是原任务与目标任务差异较大时）充当“防火墙”，保证模型表示能力的迁移；     </p>
<h3 id="tensorflow实现"><a href="#tensorflow实现" class="headerlink" title="tensorflow实现"></a>tensorflow实现</h3><h4 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h4><p>借助 <code>tf.nn.conv2d()</code> ——            </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_sample_images

<span class="token comment" spellcheck="true"># 读入一些图片</span>
dataset <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>load_sample_images<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>images<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
batch_size<span class="token punctuation">,</span> height<span class="token punctuation">,</span> width<span class="token punctuation">,</span> channels <span class="token operator">=</span> dataset<span class="token punctuation">.</span>shape

<span class="token comment" spellcheck="true"># 创建两个三维filter</span>
<span class="token comment" spellcheck="true"># ... 大小7*7，通道数由图片决定</span>
<span class="token comment" spellcheck="true"># ... 一个水平filter，一个垂直filter（只有某一行或列为1）</span>
filters_test <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">7</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">,</span> channels<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
filters_test<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span> <span class="token comment" spellcheck="true"># vertical line</span>
filters_test<span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span> <span class="token comment" spellcheck="true"># horizontal line</span>

<span class="token comment" spellcheck="true"># 图片占位符</span>
X <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span>None<span class="token punctuation">,</span> height<span class="token punctuation">,</span> width<span class="token punctuation">,</span> channels<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 添加卷积层</span>
<span class="token comment" spellcheck="true"># ... X为输入</span>
<span class="token comment" spellcheck="true"># ... filters是所用的一系列filter，列表最后一维是filter的索引</span>
<span class="token comment" spellcheck="true"># ... stride是步长，针对输入而言的，比如这里batch、行、列、通道的步长分别为1,2,2,1</span>
<span class="token comment" spellcheck="true"># ... padding为填充方式，SAME表示填零，VALID表示不填零（可能会舍弃结尾的部分元素）</span>
convolution <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>conv2d<span class="token punctuation">(</span>X<span class="token punctuation">,</span> filters<span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"SAME"</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    output <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>convolution<span class="token punctuation">,</span> feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>X<span class="token punctuation">:</span> dataset<span class="token punctuation">}</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 显示第一张图片的第二个feature map</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>output<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<p>padding参数，SAME和VALID的区别——<br><img src="/Handson-ML/12Padding.png" alt="padding">          </p>
<h4 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h4><p>借助<code>tf.nn.max_pool()</code>、<code>tf.nn.avg_pool()</code> 等——       </p>
<pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> load_sample_images

<span class="token comment" spellcheck="true"># 读入一些图片</span>
dataset <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>load_sample_images<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>images<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
batch_size<span class="token punctuation">,</span> height<span class="token punctuation">,</span> width<span class="token punctuation">,</span> channels <span class="token operator">=</span> dataset<span class="token punctuation">.</span>shape

<span class="token comment" spellcheck="true"># 图片占位符</span>
X <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span> shape<span class="token operator">=</span><span class="token punctuation">(</span>None<span class="token punctuation">,</span> height<span class="token punctuation">,</span> width<span class="token punctuation">,</span> channels<span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment" spellcheck="true"># 添加最大池化层</span>
<span class="token comment" spellcheck="true"># ... X为输入的数据</span>
<span class="token comment" spellcheck="true"># ... ksize为池化核大小，这里表示每次一张图片，池化核大小为2x2，池化核每次只应用于一个通道</span>
<span class="token comment" spellcheck="true"># ...... 注意：tensorflow不支持多对象池化，所以第一维必须是1</span>
<span class="token comment" spellcheck="true"># .......... 而且，只支持平面池化或者深度池化</span>
<span class="token comment" spellcheck="true"># .......... 也就是说，要么深度（通道）参数置为1，要么长宽都置为1</span>
<span class="token comment" spellcheck="true"># ... stride为步长，同卷积层，这里batch、行、列、通道的步长分别为1,2,2,1</span>
<span class="token comment" spellcheck="true"># ... padding为填充方式，同卷积层，这里表示不填充</span>
max_pool <span class="token operator">=</span> tf<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>max_pool<span class="token punctuation">(</span>X<span class="token punctuation">,</span> ksize<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> strides<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token string">"VALID"</span><span class="token punctuation">)</span>

<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    output <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>max_pool<span class="token punctuation">,</span> feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>X<span class="token punctuation">:</span> dataset<span class="token punctuation">}</span><span class="token punctuation">)</span>

<span class="token comment" spellcheck="true"># 显示第一张图片池化后的效果</span>
plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>output<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre>
<h3 id="内存占用计算（以卷积层为例）"><a href="#内存占用计算（以卷积层为例）" class="headerlink" title="内存占用计算（以卷积层为例）"></a>内存占用计算（以卷积层为例）</h3><p>考虑 $N_f$ 个大小为 $m_f \times n_f \times c$ 的三维filter组成的卷积层，<br>假设输入数据（比如图片）大小为 $m_i \times n_i$，每个batch有 $N_i$ 个instances，<br>那么每个filter输出feature map的大小也为 $m_i \times n_i$；        </p>
<p>此时,<br>该卷积层包含参数数量为——<br>$$ N_p = (m_f \times n_f \times c \underbrace{+1}_{\text{偏置单元}}) \times N_f $$<br>该卷积层输出的feature maps的变量总数为——<br>$$ N_v = m_i \times n_i \times N_i $$<br>该卷积层每一趟要执行的运算次数为——<br>$$ N_o = \underbrace{m_i \times n_i \times N_i}_{\text{feature maps的变量总数}} \times \underbrace{m_f \times n_f \times c}_{\text{卷积核大小}} $$        </p>
<p>比如，200个大小为 $5 \times 5 \times 3$ 的filter组成的卷积层，输入大小为 $150 \times 100$ 的三通道图片；<br>那么该层参数数量为 $ (5 \times 5 \times 3 + 1) \times 200 = 15200 $ ；<br>如果每个batch大小为1，使用float32存储变量，那么需要占用内存 $200 \times 150 \times 100 \times 32 = 96,000,000bits$ （约11.4MB）；<br>需要进行 $200 \times 150 \times 100 \times 5 \times 5 \times 3 = 225,000,000$ 次float乘法；      </p>
<p>解决内存溢出的办法：     </p>
<ol>
<li>加大步长达到降维的目的（使feature map比输入小）       </li>
<li>减少一些层      </li>
<li>使用占用空间更少的变量类型        </li>
<li>分布式运算</li>
</ol>
<h3 id="经典的CNN分类架构"><a href="#经典的CNN分类架构" class="headerlink" title="经典的CNN分类架构"></a>经典的CNN分类架构</h3><p>目前常见的CNN分类架构有LeNet-5、AlexNet(2012)、NIN(2014)、VGG-Nets(2015)、GoogLeNet(2015)、ResNet(2015)等；<br>详见 《<a href="/2018/05/02/经典的CNN分类架构?_blank">经典的CNN分类架构 | Hey~YaHei!</a>》     </p>
<h3 id="目标检测架构"><a href="#目标检测架构" class="headerlink" title="目标检测架构"></a>目标检测架构</h3><p>参见 <a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&amp;mid=2650741534&amp;idx=1&amp;sn=02dc164ffcedbf22124b97841ba67fe5&amp;chksm=871adf60b06d567690fa2328b161c012a464687768e50f812a51b5533a7d68b99af1cf8f02b8&amp;scene=0#rd" target="_blank" rel="noopener">从RCNN到SSD，这应该是最全的一份目标检测算法盘点 | 机器之心(2018)</a>【<a href="https://medium.com/@jonathan_hui/what-do-we-learn-from-region-based-object-detectors-faster-r-cnn-r-fcn-fpn-7e354377a7c9" target="_blank" rel="noopener">原文</a>】     </p>
<h3 id="CNN可视化"><a href="#CNN可视化" class="headerlink" title="CNN可视化"></a>CNN可视化</h3><p>论文：    </p>
<ol>
<li><a href="https://cs.nyu.edu/~fergus/drafts/deconv_iccv_names.pdf" target="_blank" rel="noopener">Adaptive Deconvolutional Networks for Mid and High Level Feature Learning(2011)</a> 提出反卷积技术     </li>
<li><a href="https://arxiv.org/pdf/1311.2901.pdf" target="_blank" rel="noopener">Visualizing and Understanding Convolutional Networks(2013)</a> 用反卷积技术实现CNN可视化（以AlexNet为例）    </li>
</ol>
<h3 id="网络压缩"><a href="#网络压缩" class="headerlink" title="网络压缩"></a>网络压缩</h3><p>深度神经网络面临严峻的<strong>过参数化（over-parameterization）</strong>问题，<br>如论文 <a href="http://export.arxiv.org/pdf/1306.0543" target="_blank" rel="noopener">Predicting Parameters in Deep Learning(2014)</a> 指出只给定很小一部分参数子集（约5%）就可以完整地重构剩余的参数；    </p>
<p>但事实上，参数的冗余在模型<strong>训练过程中</strong>是十分必要的，因为面临一个极其复杂的非凸优化问题，对现有基于梯度下降的优化算法而言，参数冗余保证了网络能够收敛到一个比较好的最优值。一定程度上，网络越深，参数越多，模型越复杂，最终效果也往往越好；     </p>
<p>压缩既指体积上的压缩，也指时间上的压缩。<br>绝大多数压缩算法旨在将一个庞大而复杂的<strong>预训练模型</strong>转化为一个精简的小模型；<br>按对网络结构的破坏程度分，可以分为前端压缩和后端压缩——     </p>
<ul>
<li><strong>前端压缩</strong><br>  不改变原网络结构，仅仅在原模型基础上减少网络层数或滤波器个数，可以完美适配现有的深度学习库；<br>  主要包括知识蒸馏、紧凑的模型结构设计、滤波器层面的剪枝等     </li>
<li><strong>后端压缩</strong><br>  尽可能减少模型大小，对原始网络造成极大程度的改造（往往不可逆），必须开发相应配套的运行库甚至专门的硬件设备；<br>  主要包括低秩近似、未加限制的剪枝、参数量化、二值网络等    </li>
<li>前端压缩和后端压缩是互补的关系<br>  通过相互结合，将前端压缩和后端压缩级联起来，可以在最大程度上减少模型复杂度       </li>
<li>此外，也有人试图设计更加紧凑的网络结构，对新的网络结构进行训练<br>  这也能减小模型复杂度，但不是严格意义上的网络压缩    </li>
</ul>
<!-- 妈耶！好难啊，先放一放
#### 低秩近似       
基本思想：      
CNN的卷积操作由矩阵乘法完成，权重矩阵往往稠密巨大，带来计算和存储上的巨大开销；      
可以将稠密的矩阵用若干个小规模矩阵近似重构出来，这类算法大多采用低秩近似的技术      

对于权重矩阵 $W \in R^{m \times n}$ ，用若干低秩矩阵 $M_i$ 组合来进行表示——      
$$ W = \sum^n_{i=1} \alpha_i M_i $$        
其中，$M_i \in R^{m \times n}$ 且其秩为 $r_i << min(m,n)$；       
并且可以对每个低秩矩阵进一步分解为小规模矩阵的乘积——       
$$ M_i = G_i H_i^T $$        
其中，$G_i \in R^{m \times r_i}$， $H_i \in R^{n \times r_i}$      
当 $r_i$ 很小时，可以大幅度降低总体的存储和计算开销（以全连接层为例）——     
* 原始权重矩阵 $W$      
    参数总数为 $nm$；     
    计算 $W^T X$      
    包含 $nm$ 次乘法 和 $n(m-1)$ 次加法；      
* 低秩矩阵 $W_i$     
    参数总数为 $n(m r_i + n r_i + 1)$；    
    计算 $W^T X = \sum_{i=1}^n \alpha_i M_i^T X = \sum_{i=1}^n \alpha_i H_i G_i^T X$     
    包含 $r_i(m+n) + n$ 次乘法 和 $r_i((n-1)+(m-1)) + n$ 次加法；     
    *注意：先计算 $G_i^T X$，再计算 $H_i (G_i^T X)$*       
    这里看起来参数总数反而变多了（实际上后边有更简单的表示法），但在 $r_i << min(m, n)$ 时可以明显看到计算量减少了
-->       
<h3 id="数据扩充"><a href="#数据扩充" class="headerlink" title="数据扩充"></a>数据扩充</h3><p>有效的数据扩充通过扩充训练样本数量，增加样本多样性，一方面可以避免过拟合，另一方面会给模型性能带来提升；       </p>
<h4 id="简单的数据扩充"><a href="#简单的数据扩充" class="headerlink" title="简单的数据扩充"></a>简单的数据扩充</h4><ul>
<li>图像水平翻转<br>  数据集扩充一倍    </li>
<li>随机抠取<br>  一般用较大的正方形（0.8~0.9倍的原图大小）在原图的随机位置抠取图像块；<br>  抠取次数决定数据集的扩充倍数；<br>  同时用设定好的比例抠取图像，避免了图像缩放带来的分辨率失真        </li>
<li>尺度变换<br>  将原图等比率缩放为原图的0.8、0.9、1.1、1.2、1.3等倍数；<br>  缩放次数决定数据集的扩充倍数；<br>  增加CNN在物体尺度上的鲁棒性       </li>
<li>旋转<br>  将原图旋转-30度、-15度、15度、30度等角度；<br>  旋转次数决定数据集的扩充倍数；<br>  增加CNN在方向上的鲁棒性        </li>
<li>色彩抖动<br>  在RGB颜色空间对色彩分布进行轻微扰动，在HSV颜色空间对图像饱和度、明度、色调进行轻微扰动；    </li>
</ul>
<p>实践中往往会在上述几种方式叠加使用；<br>相关实践代码可以参见：<a href="https://github.com/aleju/imgaug" target="_blank" rel="noopener">aleju/imgaug | github</a>，一个图像数据集的扩充python库     </p>
<h4 id="特殊的数据扩充"><a href="#特殊的数据扩充" class="headerlink" title="特殊的数据扩充"></a>特殊的数据扩充</h4><ul>
<li><p>Fancy PCA<br>  论文：<a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">Imagenet Classification with Deep Convolutional Neural Networks(2012)</a><br>  和<a href="/2018/05/02/经典的CNN分类架构/#AlexNet">AlexNet</a>网络一同提出；<br>  论文指出，Fancy PCA可以近似捕获自然图像的一个重要特性——<strong>物体特质与光照强度和颜色变化无关</strong>        </p>
<ol>
<li>对整个数据集的R、G、B进行PCA操作，得到特征向量 $p_i$ 和特征值 $\lambda_i$，其中 $i=1,2,3$；     </li>
<li>计算一组随机值$[p_1, p_2, p_3][\alpha_1 \lambda_1, \alpha_2 \lambda_2, \alpha_3 \lambda_3]^T$，将其作为扰动加到原像素值中；<br> 其中，$\alpha_i$ 为0均值0.1标准差的高斯分布随机值      </li>
<li>每一个epoch之后，重新选取一次$\alpha_i$进行扰动       </li>
</ol>
</li>
<li><p>监督式数据扩充<br>  海康威视在2016ImageNet竞赛的场景分类任务中提出；<br>  在以物体为中心的图像分类任务中，随机抠取图像块可以取得比较好的效果；<br>  但对于依靠图像整体蕴含的高层语义的场景分类任务中，随机抠取图像块很可能会抠取到关联性比较差的结果（比如“海滩”中抠取到“树”和“天空”）；<br>  可以借助图像标记信息解决这一问题：    </p>
<ol>
<li>根据原数据训练一个分类的初始模型     </li>
<li>利用该模型对每张图生成激活图（activation map）或热力图（heat map）<br> 可以直接将最后一层卷积层特征按深度方向加和得到；<br> 也可以参照论文 <a href="https://arxiv.org/pdf/1512.04150.pdf" target="_blank" rel="noopener">Learning Deep Features for Discriminative Localization</a> 生成分类激活图（class activation map）<br> 该热力图可以指示图像区域与场景标记之间的相关概率    </li>
<li>根据上述概率映射回原图选择较强相关的图像区域作为抠取的图像块</li>
</ol>
</li>
</ul>
<h3 id="图像预处理：中心式归一化"><a href="#图像预处理：中心式归一化" class="headerlink" title="图像预处理：中心式归一化"></a>图像预处理：中心式归一化</h3><p>在训练集上计算各通道的均值，然后对训练集、验证集、测试集上每一个像素点的各通道都减去该均值；<br>其原理在于，自然图像一般是一类平稳的数据分布，通过减均值操作可以移除图像的共性部分而凸显个体的差异；<br>比如下图通过减均值操作之后，可以发现背景部分被有效“移除”了，而只保留车、建筑等显著区域<br><img src="/Handson-ML/12Image_Preprocess.png" alt="12Image_Preprocess">     </p>
<h3 id="超参数设定"><a href="#超参数设定" class="headerlink" title="超参数设定"></a>超参数设定</h3><h4 id="输入数据像素大小"><a href="#输入数据像素大小" class="headerlink" title="输入数据像素大小"></a>输入数据像素大小</h4><p>CNN需要对输入的图像统一大小，通常为了便于GPU设备并行，都会统一将图像压缩为 $2^n$ 大小；<br>在设备、时间条件允许的情况下，一般分辨率高的数据有助于网络性能的提升，尤其是对基于注意力模型的网络；<br>一般CNN最后采用FC作为分类器，如果改变了原模型的图像分辨率，通常也需要重新设定FC输入的滤波器大小以及其他相关参数     </p>
<h4 id="卷积层参数"><a href="#卷积层参数" class="headerlink" title="卷积层参数"></a>卷积层参数</h4><p>包括卷积核大小、卷积步长、卷积核个数（即输出的特征图数量）；      </p>
<p>实践中通常采用3x3和5x5的小核，小的卷积核有以下作用：      </p>
<ol>
<li>增加模型复杂度，防止欠拟合    </li>
<li>减少参数数量     </li>
</ol>
<p>卷积操作可以选择性的搭配填充操作（padding），有以下作用：     </p>
<ol>
<li>充分利用和处理输入数据的边缘信息    </li>
<li>搭配合适的参数可以保持输入、输出大小不变，避免随着网络深度增加输入大小急剧减小<br> 对于fxf的卷积核、步长为1的卷积操作，在边缘各添加 $p=(f-1)/2$ 个像素可以维持输入输出大小不变       </li>
</ol>
<p>为了便于GPU设备方便存储，卷积核个数也即输出的特征图数量通常为 $2^n$ ；    </p>
<p>可参考：<a href="https://www.quora.com/How-can-I-decide-the-kernel-size-output-maps-and-layers-of-CNN?utm_medium=organic&amp;utm_source=google_rich_qa&amp;utm_campaign=google_rich_qa" target="_blank" rel="noopener">How can I decide the kernel size, output maps and layers of CNN? | Quora</a>  </p>
<p>论文：    </p>
<ol>
<li><a href="http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf" target="_blank" rel="noopener">Efficient BackProp(1998)</a>     </li>
<li><a href="https://arxiv.org/pdf/1606.02228v2.pdf" target="_blank" rel="noopener">Systematic evaluation of CNN advances on the ImageNet(2017)</a> 比较了ILSVRC上各种技术、模块在不同参数下的表现<br> 对应github评估项目：<a href="https://github.com/ducha-aiki/caffenet-benchmark" target="_blank" rel="noopener">ducha-aiki/caffenet-benchmark | github</a>     </li>
</ol>
<p>通常，     </p>
<ul>
<li>网络越深越好，但这是以更大的数据集、学习任务复杂度增加为代价的；     </li>
<li>batch size设为几百，具体视任务而定，批大小约大计算资源的需求就越高，批大小不宜太小（这会导致估计产生较大的偏差）；     </li>
<li>一开始使用较少的特征图数量，然后逐渐增加并且一边观察误差的变化趋势；    </li>
<li>小核可以捕捉图像的细节，大核容易丢失图像的细微特征；    </li>
<li>可以参考类似任务的网络配置；     </li>
</ul>
<h4 id="池化层参数"><a href="#池化层参数" class="headerlink" title="池化层参数"></a>池化层参数</h4><ul>
<li>池化核一般比较小，如2x2、3x3等<br>  为了不丢弃过多输入而损失网络性能，很少使用超过3x3的池化核     </li>
<li>最常用的是2x2大小、2步长的池化操作<br>  此时输出缩小为原来的四分之一，也即丢弃了75%的响应值     </li>
</ul>
<h3 id="训练技巧"><a href="#训练技巧" class="headerlink" title="训练技巧"></a>训练技巧</h3><p><strong>随机打乱训练数据</strong>：<br>信息论指出——    </p>
<blockquote>
<p>从相似的事件中学习总是比从相似事件中学习更具信息量    </p>
</blockquote>
<p>在每轮（epoch）训练中随机打乱训练数据，使得模型每次在不同批次看到“不同”的数据，<br>不仅可以提高模型收敛速度，还对模型的泛化性能有略微的提升      </p>
<p><strong>学习率设定</strong>：     </p>
<ul>
<li>初始学习率不宜过大，以0.01和0.001为宜；<br>  如果刚训练几步模型的loss就急剧上升，说明初始学习率过大       </li>
<li>使用一定的学习计划策略<br>  可参见 <a href="/2018/04/10/优化器/#学习计划（learning-schedules）">优化器/学习计划 | Hey~YaHei!</a>     </li>
<li>训练过程中观察学习曲线（loss随步数的变化）对学习率进行诊断<br>  <img src="/Handson-ML/learning_rate.png" alt="learning_rate">     </li>
</ul>
<p><strong>批规范化操作（BN操作）</strong>：<br>参见 <a href="/2018/04/08/梯度消失与梯度爆炸/#批量归一化（Batch-Normalization-BN）">梯度消失与梯度爆炸/批量归一化 | Hey~YaHei!</a>     </p>
<p><strong>优化器</strong>：<br>参见 <a href="/2018/04/10/优化器/">优化器 | Hey~YaHei!</a>     </p>
<p><strong>微调预训练好的神经网络</strong>：<br>用目标任务数据在预训练模型上继续进行训练过程；      </p>
<ul>
<li>网络已经在原始数据上收敛，微调时采用更小的学习率（一般在$10^{-4}$及其以下）    </li>
<li>CNN浅层有更强的泛化特征，深层对应更抽象的语义特征；<br>  微调时往往对前层更新的少，对深层更新的多，故可以设置不同的学习率；      </li>
<li>微调策略   <ul>
<li>数据较少且任务非常相似时，可仅微调最后的几层    </li>
<li>数据较多且任务相似时，可以微调更多甚至全部的网络层    </li>
<li>当数据较少、差异较大时，可以尝试微调，但不一定能成功<br>  这种情况下还可以借助<strong>部分原始数据与目标数据协同训练</strong>；<br>  论文：<a href="https://arxiv.org/pdf/1702.08690.pdf" target="_blank" rel="noopener">Borrowing Treasures from the Wealthy: Deep Transfer Learning through Selective Joint Fine-tuning(2017)</a><br>  在浅层特征空间选择目标数据的近邻作为协同训练的原始数据子集；<br>  微调阶段改造为多目标学习任务：将目标任务基于原始数据子集、将目标任务基于全部目标数据；     </li>
</ul>
</li>
</ul>
<hr>
<p>2018-05-02<br>将经典的CNN分类架构抽离出来作为单独一篇博文：<br>《<a href="/2018/05/02/经典的CNN分类架构?_blank">经典的CNN分类架构 | Hey~YaHei!</a>》     </p>
<hr>
<p>2018-05-07<br>将池化层原理部分抽离出来作为单独一篇博文：<br>详见 《<a href="/2018/05/07/漫谈池化层?_blank">漫谈池化层 | Hey~YaHei!</a>》         </p>

        
    

    
</div>


                

                <!-- Post Comments -->
                
                    
    <!-- 使用 来必力 -->
<div id="livere-comment">
    <div id="lv-container" data-id="city" data-uid="MTAyMC8zOTE5OS8xNTcyNg==">
	<script type="text/ls-javascript" id="livere-comment-js">
   (function(d, s) {
       var j, e = d.getElementsByTagName(s)[0];
       if (typeof LivereTower === 'function') { return; }
       j = d.createElement(s);
       j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
       j.async = true;
       e.parentNode.insertBefore(j, e);
   })(document, 'script');
	</script>
</div>
</div>
<style>
    #livere-comment{
        background-color: #eee;
        padding: 2pc;
    }
</style>

                
            </div>

            <!-- Post Prev & Next Nav -->
            <nav class="material-nav mdl-color-text--grey-50 mdl-cell mdl-cell--12-col">
    <!-- Prev Nav -->
    
        <a href="/2018/04/22/RNN/" id="post_nav-newer" class="prev-content">
            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation">
                <i class="material-icons">arrow_back</i>
            </button>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            新篇
        </a>
    

    <!-- Section Spacer -->
    <div class="section-spacer"></div>

    <!-- Next Nav -->
    
        <a href="/2018/04/11/正则化技术/" id="post_nav-older" class="next-content">
            旧篇
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation">
                <i class="material-icons">arrow_forward</i>
            </button>
        </a>
    
</nav>

        </div>
    </div>



                    
                        <!-- Overlay For Active Sidebar -->
<div class="sidebar-overlay"></div>

<!-- Material sidebar -->
<aside id="sidebar" class="sidebar sidebar-colored sidebar-fixed-left" role="navigation">
    <div id="sidebar-main">
        <!-- Sidebar Header -->
        <div class="sidebar-header header-cover" style="background-image: url(/img/sidebar_header.png);">
    <!-- Top bar -->
    <div class="top-bar"></div>

    <!-- Sidebar toggle button -->
    <button type="button" class="sidebar-toggle mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon" style="display: initial;" data-upgraded=",MaterialButton,MaterialRipple">
        <i class="material-icons">clear_all</i>
        <span class="mdl-button__ripple-container">
            <span class="mdl-ripple">
            </span>
        </span>
    </button>

    <!-- Sidebar Avatar -->
    <div class="sidebar-image">
        <img src="/imgs/avatar2.jpg" alt="YaHei's avatar">
    </div>

    <!-- Sidebar Email -->
    <a data-toggle="dropdown" class="sidebar-brand" href="#settings-dropdown">
        hey.yahei.zk@gamil.com
        <b class="caret"></b>
    </a>
</div>


        <!-- Sidebar Navigation  -->
        <ul class="nav sidebar-nav">
    <!-- User dropdown  -->
    <li class="dropdown">
        <ul id="settings-dropdown" class="dropdown-menu">
            
                <li>
                    <a href="mailto: hey.yahei.zk@gamil.com" target="_blank" title="Email Me">
                        
                            <i class="material-icons sidebar-material-icons sidebar-indent-left1pc-element">email</i>
                        
                        Email Me
                    </a>
                </li>
            
                <li>
                    <a href="http://music.163.com/#/user/home?id=421946266" target="_blank" title="Netease Cloud Music">
                        
                            <i class="material-icons sidebar-material-icons sidebar-indent-left1pc-element">music_note</i>
                        
                        Netease Cloud Music
                    </a>
                </li>
            
        </ul>
    </li>

    <!-- Homepage -->
    
        <li id="sidebar-first-li">
            <a href="/">
                
                    <i class="material-icons sidebar-material-icons">home</i>
                
                主页
            </a>
        </li>
        
    

    <!-- Archives  -->
    

    <!-- Categories  -->
    

    <!-- Pages  -->
    
        <li>
            <a href="/tags" title="标签云">
                
                    <i class="material-icons sidebar-material-icons">cloud</i>
                
                标签云
            </a>
        </li>
        
    
        <li>
            <a href="/timeline" title="时间轴">
                
                    <i class="material-icons sidebar-material-icons">event_note</i>
                
                时间轴
            </a>
        </li>
        
    
        <li>
            <a href="/gallery" title="图库">
                
                    <i class="material-icons sidebar-material-icons">photo_library</i>
                
                图库
            </a>
        </li>
        
    

    <!-- Article Number  -->
    
        <li>
            <a href="/archives">
                文章总数
                <span class="sidebar-badge">34</span>
            </a>
        </li>
        
    
</ul>


        <!-- Sidebar Footer -->
        <!--
I'm glad you use this theme, the development is no so easy, I hope you can keep the copyright, I will thank you so much.
If you still want to delete the copyrights, could you still retain the first one? Which namely "Theme Material"
It will not impact the appearance and can give developers a lot of support :)

很高兴您使用并喜欢该主题，开发不易 十分谢谢与希望您可以保留一下版权声明。
如果您仍然想删除的话 能否只保留第一项呢？即 "Theme Material"
它不会影响美观并可以给开发者很大的支持和动力。 :)
-->

<!-- Sidebar Divider -->

    <div class="sidebar-divider"></div>


<!-- Theme Material -->

    <a href="https://github.com/viosey/hexo-theme-material"  class="sidebar-footer-text-a" target="_blank">
        <div class="sidebar-text mdl-button mdl-js-button mdl-js-ripple-effect sidebar-footer-text-div" data-upgraded=",MaterialButton,MaterialRipple">
            主题 - Material
            <span class="sidebar-badge badge-circle">i</span>
        </div>
    </a>


<!-- Help & Support -->
<!--

-->

<!-- Feedback -->
<!--

-->

<!-- About Theme -->
<!--

-->

    </div>

    <!-- Sidebar Image -->
    

</aside>

                    

                    
                        <!-- Footer Top Button -->
                        <div id="back-to-top" class="toTop-wrap">
    <a href="#top" class="toTop">
        <i class="material-icons footer_top-i">expand_less</i>
    </a>
</div>

                    

                    <!--Footer-->
<footer class="mdl-mini-footer" id="bottom">
    
        <!-- Paradox Footer Left Section -->
        <div class="mdl-mini-footer--left-section sns-list">
    <!-- Twitter -->
    

    <!-- Facebook -->
    

    <!-- Google + -->
    

    <!-- Weibo -->
    

    <!-- Instagram -->
    

    <!-- Tumblr -->
    

    <!-- Github -->
    
        <a href="http://github.com/hey-yahei" target="_blank">
            <button class="mdl-mini-footer--social-btn social-btn footer-sns-github">
                <span class="visuallyhidden">Github</span>
            </button><!--
     --></a>
    

    <!-- LinkedIn -->
    

    <!-- Zhihu -->
    

    <!-- Bilibili -->
    

    <!-- Telegram -->
    

    <!-- V2EX -->
    

    <!-- Segmentfault -->
    
</div>


        <!--Copyright-->
        <div id="copyright">
            Copyright&nbsp;©&nbsp;<span year></span>&nbsp;Hey~YaHei!
            
                <br>
                
                    <a href="http://www.miitbeian.gov.cn" rel="nofollow">浙ICP备17042598号-1</a>
                
            
        </div>

        <!-- Paradox Footer Right Section -->

        <!--
        I am glad you use this theme, the development is no so easy, I hope you can keep the copyright.
        It will not impact the appearance and can give developers a lot of support :)

        很高兴您使用该主题，开发不易，希望您可以保留一下版权声明。
        它不会影响美观并可以给开发者很大的支持。 :)
        -->

        <div class="mdl-mini-footer--right-section">
            <div>
                <div class="footer-develop-div">Powered by <a href="https://hexo.io" target="_blank" class="footer-develop-a">Hexo</a></div>
                <div class="footer-develop-div">Theme - <a href="https://github.com/viosey/hexo-theme-material" target="_blank" class="footer-develop-a">Material</a></div>
            </div>
        </div>
    
</footer>


                    <!-- Import JS File -->

    <script>lsloader.load("lazyload_js","/js/lazyload.min.js?1BcfzuNXqV+ntF6gq+5X3Q==", true)</script>



    <script>lsloader.load("js_js","/js/js.min.js?Bn9UzEm8RrBSxqyZB0zPjA==", true)</script>



    <script>lsloader.load("np_js","/js/nprogress.js?pl3Qhb9lvqR1FlyLUna1Yw==", true)</script>


<script type="text/ls-javascript" id="NProgress-script">
    NProgress.configure({
        showSpinner: true
    });
    NProgress.start();
    $('#nprogress .bar').css({
        'background': '#29d'
    });
    $('#nprogress .peg').css({
        'box-shadow': '0 0 10px #29d, 0 0 15px #29d'
    });
    $('#nprogress .spinner-icon').css({
        'border-top-color': '#29d',
        'border-left-color': '#29d'
    });
    setTimeout(function() {
        NProgress.done();
        $('.fade').removeClass('out');
    }, 800);
</script>



    
        <script>lsloader.load("sm_js","/js/smoothscroll.js?lOy/ACj5suSNi7ZVFVbpFQ==", true)</script>
    







   





<!-- UC Browser Compatible -->
<script>
	var agent = navigator.userAgent.toLowerCase();
	if(agent.indexOf('ucbrowser')>0) {
		document.write('<link rel="stylesheet" href="/css/uc.css">');
	   alert('由于 UC 浏览器使用极旧的内核，而本网站使用了一些新的特性。\n为了您能更好的浏览，推荐使用 Chrome 或 Firefox 浏览器。');
	}
</script>

<!-- Import prettify js  -->



<!-- Window Load -->
<!-- add class for prettify -->
<script type="text/ls-javascript" id="window-load">
    $(window).on('load', function() {
        // Post_Toc parent position fixed
        $('.post-toc-wrap').parent('.mdl-menu__container').css('position', 'fixed');
    });

    
    
</script>

<!-- MathJax Load-->

    <script type="text/x-mathjax-config">
    MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
        tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
        TeX: {  noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
        messageStyle: "none"
    });
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

    <script src="https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>




<!-- Bing Background -->


<script type="text/ls-javascript" id="lazy-load">
    // Offer LazyLoad
    queue.offer(function(){
        $('.lazy').lazyload({
            effect : 'show'
        });
    });

    // Start Queue
    $(document).ready(function(){
        setInterval(function(){
            queue.execNext();
        },200);
    });
</script>

<!-- Custom Footer -->



<script>
    var copyrightNow = new Date().getFullYear();
    var textContent = document.querySelector('span[year]')

    copyrightSince = 2017;
    if (copyrightSince === copyrightNow||copyrightSince === 0000) {
        textContent.textContent = copyrightNow
    } else {
        textContent.textContent = copyrightSince + ' - ' + copyrightNow
    }

    (function(){
        var scriptList = document.querySelectorAll('script[type="text/ls-javascript"]')

        for (var i = 0; i < scriptList.length; ++i) {
            var item = scriptList[i];
            lsloader.runInlineScript(item.id,item.id);
        }
    })()
console.log('\n %c © Material Theme | Version: 1.5.6 | https://github.com/viosey/hexo-theme-material %c \n', 'color:#455a64;background:#e0e0e0;padding:5px 0;border-top-left-radius:5px;border-bottom-left-radius:5px;', 'color:#455a64;background:#e0e0e0;padding:5px 0;border-top-right-radius:5px;border-bottom-right-radius:5px;');
</script>

                </main>
            </div>
        </body>
    
</html>

<script type="text/javascript">
    var aTagArr = [].slice.apply(document.getElementsByTagName("a"));
    aTagArr.forEach(function (e, i) {
        if( e.href.lastIndexOf("_blank") > -1 ){
            e.target = "_blank";
            e.href = e.href.replace("?_blank", "");
        }
    });
</script>